{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup django env\n",
    "\n",
    "## db server\n",
    "\n",
    "## environment\n",
    "\n",
    "# confirm apis\n",
    "\n",
    "## crop pic by skimage?\n",
    "\n",
    "# retrieve\n",
    "\n",
    "## nmslib \n",
    "这是一个大问题，需要更多的算法，做更好的比较\n",
    "## plot nmslib result on x-y plot\n",
    "\n",
    "# aligner\n",
    "初步认为是因为人脸没有对齐，导致索引极差。但这个事情应分析下facenet的训练要求才能解决\n",
    "\n",
    "# f1 score\n",
    "\n",
    "\n",
    "# 想法\n",
    "把这几个识别库单独拿出来，做成一个开发包，与Django和Celery分开使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import django\n",
    "def start_local():\n",
    "    os.environ[\"DOCKER_MODE\"] = \"true\"\n",
    "    os.environ[\"RABBIT_HOST\"]= \"localhost\"\n",
    "    os.environ[\"RABBIT_USER\"] = \"dvauser\"\n",
    "    os.environ[\"RABBIT_PASS\"] = \"localpass\"\n",
    "\n",
    "    # db\n",
    "    os.environ[\"DB_HOST\"] = \"localhost\"\n",
    "    os.environ[\"DB_NAME\"] = \"postgres\"\n",
    "    os.environ[\"DB_USER\"] = \"pgdbuser\"\n",
    "    os.environ[\"DB_PASS\"] = \"pgdbpass\"\n",
    "\n",
    "    os.environ[\"LAUNCH_SERVER\"] = \"1\"\n",
    "    os.environ[\"LAUNCH_BY_NAME_indexer_inception\"] = \"1\"\n",
    "    os.environ[\"LAUNCH_BY_NAME_indexer_facenet\"] = \"1\"\n",
    "    os.environ[\"LAUNCH_BY_NAME_retriever_inception\"] = \"1\"\n",
    "    os.environ[\"LAUNCH_BY_NAME_retriever_facenet\"] = \"1\"\n",
    "    os.environ[\"LAUNCH_BY_NAME_detector_coco\"] = \"1\"\n",
    "    os.environ[\"LAUNCH_BY_NAME_analyzer_crnn\"] = \"1\"\n",
    "    os.environ[\"LAUNCH_BY_NAME_analyzer_tagger\"] = \"1\"\n",
    "    os.environ[\"LAUNCH_BY_NAME_detector_face\"] = \"1\"\n",
    "    os.environ[\"LAUNCH_Q_qclusterer\"] = \"1\"\n",
    "    os.environ[\"LAUNCH_Q_qextract\"] = \"1\"\n",
    "    os.environ[\"LAUNCH_SCHEDULER\"] = \"1\"\n",
    "    # export  TEST=1\n",
    "    os.environ[\"AUTH_DISABLED\"] = \"1\"\n",
    "    dva_home = \"/home/tom/ai/DeepVideoAnalytics\"\n",
    "    sys.path.append(os.path.abspath(dva_home))\n",
    "    \n",
    "    os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"dva.settings\")\n",
    "    django.setup()\n",
    "    \n",
    "start_local()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmp = \"/home/tom/ai.dataset.images/Face/222/222_0.bmp\"\n",
    "temppath = \"/home/tom/ai.dataset.images.tmp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Loading facenet , first apply / query will be slower\n",
      "WARNING:root:Creating a session facenet , first apply / query will be slower\n"
     ]
    }
   ],
   "source": [
    "import dvalib.indexer\n",
    "index = dvalib.indexer.FacenetIndexer(os.path.join(\"/home/tom/ai/DeepVideoAnalytics/dva/media/indexers/2\", \"facenet.pb\"))\n",
    "index.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from dvalib import detector\n",
    "reload(detector)\n",
    "detect =detector.FaceDetector()\n",
    "detect.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dvalib.dlib import AlignDlib\n",
    "aligner = AlignDlib(os.path.join(\"/home/tom/ai/models/dlib\",\"shape_predictor_68_face_landmarks.dat\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dvalib import retriever\n",
    "args = {}\n",
    "args[\"components\"] =16 # pca component\n",
    "args[\"m\"] = 4 # totol number of fine codes\n",
    "args[\"v\"] = 8 # number of cluster per coarse quntizer\n",
    "args[\"sub\"] = 256 # the number of cluster to train per subquantizer\n",
    "args['proto_filename'] = os.path.join(temppath, \"retriever.proto\")\n",
    "args['proto_filename'].replace('.proto','.P.npy')\n",
    "args['proto_filename'].replace('.proto','.mu.npy')\n",
    "args['proto_filename'].replace('.proto', '.pca.pkl')\n",
    "args['proto_filename'].replace('.proto', '_lmdb')\n",
    "args['proto_filename'].replace('.proto', '.permuted_inds.pkl')\n",
    "\n",
    "lopq = retriever.LOPQRetriever(\"lopq\", args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "FaceDetector instance has no attribute 'cropLargest'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6c0df7e3cece>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmisc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mcrop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcropLargest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpng\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;31m#misc.imshow(crop)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: FaceDetector instance has no attribute 'cropLargest'"
     ]
    }
   ],
   "source": [
    "import skimage.io as io\n",
    "import os.path\n",
    "from scipy import misc\n",
    "if not os.path.exists(temppath):\n",
    "    os.mkdir(temppath)\n",
    "basename = os.path.basename(bmp)\n",
    "dirname  = os.path.dirname(bmp)\n",
    "png = os.path.join(temppath, basename.split(\".\")[0] + \".png\")\n",
    "image = io.imread(bmp)\n",
    "io.imsave(png, image)\n",
    "#misc.imshow(image)\n",
    "\n",
    "import scipy\n",
    "from scipy import misc\n",
    "crop = detect.cropLargest(misc.imread(png))\n",
    "#misc.imshow(crop)\n",
    "\n",
    "al = aligner.align(96, crop)\n",
    "#misc.imshow(al)\n",
    "\n",
    "cropfile = os.path.join(temppath, (basename.split('.')[0]+ \"crop\"+\".png\"))\n",
    "io.imsave(cropfile, al)\n",
    "#detect.cropLargestToFile(png, cropfile)\n",
    "\n",
    "misc.imshow(al)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "GetNext() failed because the iterator has not been initialized. Ensure that you have run the initializer operation for this iterator before getting the next element.\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?,160,160,3], <unknown>], output_types=[DT_FLOAT, DT_STRING], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Iterator)]]\n\nCaused by op u'IteratorGetNext', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/lib/python2.7/dist-packages/tornado/ioloop.py\", line 866, in start\n    handler_func(fd_obj, events)\n  File \"/usr/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2828, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-5ddba07d6dbd>\", line 3, in <module>\n    index.load()\n  File \"dvalib/indexer.py\", line 273, in load\n    self.image, self.fname = self.iterator.get_next()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/data/python/ops/dataset_ops.py\", line 304, in get_next\n    name=name))\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 379, in iterator_get_next\n    output_shapes=output_shapes, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nFailedPreconditionError (see above for traceback): GetNext() failed because the iterator has not been initialized. Ensure that you have run the initializer operation for this iterator before getting the next element.\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?,160,160,3], <unknown>], output_types=[DT_FLOAT, DT_STRING], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Iterator)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-71e1263992f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeat\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpng\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfeat_head\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpng\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dot(feat,feat)={}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dot(head, head)={}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat_head\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat_head\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tom/z.git.github.beautycpp.ai/DeepVideoAnalytics/dvalib/indexer.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, image_path)\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilenames_placeholder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: GetNext() failed because the iterator has not been initialized. Ensure that you have run the initializer operation for this iterator before getting the next element.\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?,160,160,3], <unknown>], output_types=[DT_FLOAT, DT_STRING], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Iterator)]]\n\nCaused by op u'IteratorGetNext', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/lib/python2.7/dist-packages/tornado/ioloop.py\", line 866, in start\n    handler_func(fd_obj, events)\n  File \"/usr/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2828, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-5ddba07d6dbd>\", line 3, in <module>\n    index.load()\n  File \"dvalib/indexer.py\", line 273, in load\n    self.image, self.fname = self.iterator.get_next()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/data/python/ops/dataset_ops.py\", line 304, in get_next\n    name=name))\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 379, in iterator_get_next\n    output_shapes=output_shapes, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nFailedPreconditionError (see above for traceback): GetNext() failed because the iterator has not been initialized. Ensure that you have run the initializer operation for this iterator before getting the next element.\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?,160,160,3], <unknown>], output_types=[DT_FLOAT, DT_STRING], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Iterator)]]\n"
     ]
    }
   ],
   "source": [
    "feat      = np.squeeze(index.apply(png))\n",
    "feat_head = np.squeeze(index.apply(png))\n",
    "\n",
    "print(\"dot(feat,feat)={}\".format(np.dot(feat,feat)))\n",
    "print(\"dot(head, head)={}\".format(np.dot(feat_head, feat_head)))\n",
    "print(\"dot(feat, head)={}\".format(np.dot(feat, feat_head)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_path=/home/tom/ai.dataset.images.tmp/222_0.png\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "GetNext() failed because the iterator has not been initialized. Ensure that you have run the initializer operation for this iterator before getting the next element.\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?,160,160,3], <unknown>], output_types=[DT_FLOAT, DT_STRING], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Iterator)]]\n\nCaused by op u'IteratorGetNext', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/lib/python2.7/dist-packages/tornado/ioloop.py\", line 866, in start\n    handler_func(fd_obj, events)\n  File \"/usr/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2828, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-5ddba07d6dbd>\", line 3, in <module>\n    index.load()\n  File \"dvalib/indexer.py\", line 273, in load\n    self.image, self.fname = self.iterator.get_next()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/data/python/ops/dataset_ops.py\", line 304, in get_next\n    name=name))\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 379, in iterator_get_next\n    output_shapes=output_shapes, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nFailedPreconditionError (see above for traceback): GetNext() failed because the iterator has not been initialized. Ensure that you have run the initializer operation for this iterator before getting the next element.\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?,160,160,3], <unknown>], output_types=[DT_FLOAT, DT_STRING], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Iterator)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-834c55aa658f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"image_path={}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpng\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpng\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/tom/z.git.github.beautycpp.ai/DeepVideoAnalytics/dvalib/indexer.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, image_path)\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilenames_placeholder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: GetNext() failed because the iterator has not been initialized. Ensure that you have run the initializer operation for this iterator before getting the next element.\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?,160,160,3], <unknown>], output_types=[DT_FLOAT, DT_STRING], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Iterator)]]\n\nCaused by op u'IteratorGetNext', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/lib/python2.7/dist-packages/tornado/ioloop.py\", line 866, in start\n    handler_func(fd_obj, events)\n  File \"/usr/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2828, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-5ddba07d6dbd>\", line 3, in <module>\n    index.load()\n  File \"dvalib/indexer.py\", line 273, in load\n    self.image, self.fname = self.iterator.get_next()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/data/python/ops/dataset_ops.py\", line 304, in get_next\n    name=name))\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 379, in iterator_get_next\n    output_shapes=output_shapes, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nFailedPreconditionError (see above for traceback): GetNext() failed because the iterator has not been initialized. Ensure that you have run the initializer operation for this iterator before getting the next element.\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?,160,160,3], <unknown>], output_types=[DT_FLOAT, DT_STRING], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Iterator)]]\n"
     ]
    }
   ],
   "source": [
    "print(\"image_path={}\".format(png))\n",
    "index.apply(png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99999988"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import skimage.io as io\n",
    "import collections\n",
    "PicRec = collections.namedtuple(\"PicRec\",[\"path\",\"feat\"])\n",
    "def detect_dir(path, dest_path) :\n",
    "    result = []\n",
    "    faces = os.listdir(path)\n",
    "    for f in faces:\n",
    "        picpath = os.path.join(path, f)\n",
    "        dest_file = os.path.join(dest_path,f)\n",
    "        hasface = detect.cropLargestToFile(picpath, dest_file)\n",
    "        \n",
    "        if hasface:\n",
    "            feat = np.squeeze(index.apply(dest_file))\n",
    "            result.append(PicRec(path=f.split(\"_\")[0], feat=feat))\n",
    "        else :\n",
    "            print(\"fail to detect face in {}\".format(path))\n",
    "    return result\n",
    "dest_dir = \"/home/tom/ai.dataset.images.tmp/test.temp\"\n",
    "if not os.path.exists(dest_dir):\n",
    "    os.mkdir(dest_dir)\n",
    "r = detect_dir(\"/home/tom/ai.dataset.images.tmp/test\", dest_dir)\n",
    "np.dot(r[0].feat, r[1].feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fail to detect face in /home/tom/ai.dataset.images.tmp/Face_DB_4_ms\n",
      "fail to detect face in /home/tom/ai.dataset.images.tmp/Face_DB_4_ms\n"
     ]
    }
   ],
   "source": [
    "face_dir = \"/home/tom/ai.dataset.images.tmp/Face_DB_4_ms\"\n",
    "test_dir = \"/home/tom/ai.dataset.images.tmp/Face_Test_ms\"\n",
    "crop_face_dir = \"/home/tom/ai.dataset.images.tmp/Face_DB_4_ms_crop\"\n",
    "crop_test_dir = \"/home/tom/ai.dataset.images.tmp/Face_Test_ms_crop\"\n",
    "\n",
    "if not os.path.exists(crop_face_dir) :\n",
    "    os.mkdir(crop_face_dir)\n",
    "if not os.path.exists(crop_test_dir) :\n",
    "    os.mkdir(crop_test_dir)\n",
    "    \n",
    "#os.mkdir(crop_test_dir)\n",
    "valid = detect_dir(test_dir, crop_test_dir)\n",
    "train = detect_dir(face_dir, crop_face_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1598, 128)\n",
      "(501, 128)\n"
     ]
    }
   ],
   "source": [
    "def save_feat(data, path):\n",
    "    feats = [ d.feat for d in data ]\n",
    "    arr = np.array(feats)\n",
    "    print(arr.shape)\n",
    "    np.save(path, arr)\n",
    "    \n",
    "save_feat(train, \"train.npy\")\n",
    "save_feat(valid, \"valid.npy\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([10,  0, 77,  6, 86, 65, 43, 50, 71, 38], dtype=int32),\n",
       " array([ 0.        ,  0.        ,  0.00017393,  0.00023609,  0.00036091,\n",
       "         0.00076026,  0.00902432,  0.01111245,  0.01119417,  0.03453648], dtype=float32))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os.path\n",
    "import nmslib \n",
    "import numpy as np\n",
    "\n",
    "INDEX_DIR='indices'    \n",
    "import shutil\n",
    "if os.path.exists(INDEX_DIR):\n",
    "    shutil.rmtree(INDEX_DIR)\n",
    "\n",
    "class NmslibReuseIndex:\n",
    "    def __init__(self, metric, method_name, index_param, save_index, query_param):\n",
    "        self._nmslib_metric = {'angular': 'cosinesimil', 'euclidean': 'l2'}[metric]\n",
    "        self._method_name = method_name\n",
    "        self._save_index = save_index\n",
    "        self._index_param = index_param\n",
    "        self._query_param = query_param\n",
    "        self.name = 'Nmslib(method_name=%s, index_param=%s, query_param=%s)' % (\n",
    "            method_name, index_param, query_param)\n",
    "        \n",
    "        self._index_name = os.path.join(INDEX_DIR, \"nmslib_%s_%s_%s\" % (\n",
    "            self._method_name, metric, '_'.join(self._index_param))) \n",
    "\n",
    "        d = os.path.dirname(self._index_name)\n",
    "        if not os.path.exists(d):\n",
    "          os.makedirs(d)\n",
    "        \n",
    "        self._index = nmslib.init(self._nmslib_metric)\n",
    "\n",
    "    def add(self, i, x) :\n",
    "        self._index.addDataPoint(i,x)\n",
    "        \n",
    "    def fit(self, X):\n",
    "        if self._method_name == 'vptree':\n",
    "            # To avoid this issue:\n",
    "            # terminate called after throwing an instance of 'std::runtime_error'\n",
    "            # what():  The data size is too small or the bucket size is too big. Select the parameters so that <total # of records> is NOT less than <bucket size> * 1000\n",
    "            # Aborted (core dumped)\n",
    "            self._index_param.append('bucketSize=%d' % min(int(X.shape[0] * 0.0005), 1000))\n",
    "                                        \n",
    "        for i, x in enumerate(X):\n",
    "            self._index.addDataPoint(i, x)\n",
    "\n",
    "\n",
    "        if os.path.exists(self._index_name):\n",
    "            print \"Loading index from file\"\n",
    "            self._index.loadIndex(self._index_name)\n",
    "        else:\n",
    "            self._index.createIndex(self._index_param)\n",
    "            if self._save_index: \n",
    "              self._index.saveIndex(self._index_name)\n",
    "        #self._index.setQueryTimeParams(self._query_param)\n",
    "        \n",
    "\n",
    "    def query(self, v, n):\n",
    "        return self._index.knnQuery( v, k=n)\n",
    "\n",
    "    def freeIndex(self):\n",
    "        self._index = None\n",
    "        \n",
    "class FALCONN(object):\n",
    "    def __init__(self, metric, num_bits, num_tables, num_probes):\n",
    "        self.name = 'FALCONN(K={}, L={}, T={})'.format(num_bits, num_tables, num_probes)\n",
    "        self._metric = metric\n",
    "        self._num_bits = num_bits\n",
    "        self._num_tables = num_tables\n",
    "        self._num_probes = num_probes\n",
    "        self._center = None\n",
    "        self._params = None\n",
    "        self._index = None\n",
    "        self._buf = None\n",
    "\n",
    "    def fit(self, X):\n",
    "        if X.dtype != numpy.float32:\n",
    "            X = X.astype(numpy.float32)\n",
    "        if self._metric == 'angular':\n",
    "            X /= numpy.linalg.norm(X, axis=1).reshape(-1,  1)\n",
    "        self._center = numpy.mean(X, axis=0)\n",
    "        X -= self._center\n",
    "        import falconn\n",
    "        self._params = falconn.LSHConstructionParameters()\n",
    "        self._params.dimension = X.shape[1]\n",
    "        self._params.distance_function = 'euclidean_squared'\n",
    "        self._params.lsh_family = 'cross_polytope'\n",
    "        falconn.compute_number_of_hash_functions(self._num_bits, self._params)\n",
    "        self._params.l = self._num_tables\n",
    "        self._params.num_rotations = 1\n",
    "        self._params.num_setup_threads = 0\n",
    "        self._params.storage_hash_table = 'flat_hash_table'\n",
    "        self._params.seed = 95225714\n",
    "        self._index = falconn.LSHIndex(self._params)\n",
    "        self._index.setup(X)\n",
    "        self._index.set_num_probes(self._num_probes)\n",
    "        self._buf = numpy.zeros((X.shape[1],), dtype=numpy.float32)\n",
    "\n",
    "    def query(self, v, n):\n",
    "        numpy.copyto(self._buf, v)\n",
    "        if self._metric == 'angular':\n",
    "            self._buf /= numpy.linalg.norm(self._buf)\n",
    "        self._buf -= self._center\n",
    "        return self._index.find_k_nearest_neighbors(self._buf, n)\n",
    "\n",
    "data = np.random.randn(100, 2).astype(np.float32)\n",
    "index = NmslibReuseIndex(\"angular\", \"hnsw\", {\"post\":2}, False, {\"k\":10})\n",
    "index.fit(data)\n",
    "index.query(data[0], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = NmslibReuseIndex(\"euclidean\", \"hnsw\", {\"post\":2}, False, {\"k\":10})\n",
    "names = []\n",
    "for i, (name,feat) in enumerate(train):\n",
    "    index.add(i, feat)\n",
    "    names.append(name)\n",
    "\n",
    "index.fit([])\n",
    "\n",
    "RecRec = collections.namedtuple(\"RecRec\",[\"target\",\"result\", \"similarity\"])\n",
    "query= []\n",
    "for i, (name, feat) in enumerate(valid):\n",
    "    r = index.query(feat, 1)\n",
    "    if len(r[0]) > 0:\n",
    "        rec = RecRec(target=name, result=names[r[0][0]], similarity=1.0-r[1][0])\n",
    "    else:\n",
    "        rec = RecRec(target=name, result=\"\", similarity=0.0)\n",
    "    query.append(rec)\n",
    "    \n",
    "face_test_f1_dir = \"/home/tom/ai.dataset.images/face_test_f1\"\n",
    "fn = os.path.join(face_test_f1_dir, \"facenet_test.csv\")\n",
    "with open(fn,\"w\") as f:\n",
    "    f.write(\"target,result,similarity\\n\")\n",
    "    for target, result, similarity in query:\n",
    "        f.write(\"{},{},{}\\n\".format(target, result,similarity))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_names_path = \"db_names.txt\"       \n",
    "db_feats_path = \"db_feats.txt\"\n",
    "def save_index(featpath, namepath, nf):\n",
    "    with open(featpath,\"w\") as f:\n",
    "        with open(namepath,\"w\") as fnames:\n",
    "            for i, (name, feat) in enumerate(nf):\n",
    "                fnames.write(\"{}\\n\".format(name))\n",
    "                f.write(\"{},{}\\n\".format(name, \",\".join([ str(featvalue) for featvalue in feat])))\n",
    "save_index( \"db_feats.txt\", \"db_names.txt\", train)\n",
    "save_index( \"va_feats.txt\", \"va_names.txt\", valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
