{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup django env\n",
    "\n",
    "## db server\n",
    "\n",
    "## environment\n",
    "\n",
    "# confirm apis\n",
    "\n",
    "## crop pic by skimage?\n",
    "\n",
    "# retrieve\n",
    "\n",
    "## nmslib \n",
    "这是一个大问题，需要更多的算法，做更好的比较\n",
    "## plot nmslib result on x-y plot\n",
    "\n",
    "# aligner\n",
    "初步认为是因为人脸没有对齐，导致索引极差。但这个事情应分析下facenet的训练要求才能解决\n",
    "\n",
    "# f1 score\n",
    "\n",
    "\n",
    "# 想法\n",
    "把这几个识别库单独拿出来，做成一个开发包，与Django和Celery分开使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import django\n",
    "def start_local():\n",
    "    os.environ[\"DOCKER_MODE\"] = \"true\"\n",
    "    os.environ[\"RABBIT_HOST\"]= \"localhost\"\n",
    "    os.environ[\"RABBIT_USER\"] = \"dvauser\"\n",
    "    os.environ[\"RABBIT_PASS\"] = \"localpass\"\n",
    "\n",
    "    # db\n",
    "    os.environ[\"DB_HOST\"] = \"localhost\"\n",
    "    os.environ[\"DB_NAME\"] = \"postgres\"\n",
    "    os.environ[\"DB_USER\"] = \"pgdbuser\"\n",
    "    os.environ[\"DB_PASS\"] = \"pgdbpass\"\n",
    "\n",
    "    os.environ[\"LAUNCH_SERVER\"] = \"1\"\n",
    "    os.environ[\"LAUNCH_BY_NAME_indexer_inception\"] = \"1\"\n",
    "    os.environ[\"LAUNCH_BY_NAME_indexer_facenet\"] = \"1\"\n",
    "    os.environ[\"LAUNCH_BY_NAME_retriever_inception\"] = \"1\"\n",
    "    os.environ[\"LAUNCH_BY_NAME_retriever_facenet\"] = \"1\"\n",
    "    os.environ[\"LAUNCH_BY_NAME_detector_coco\"] = \"1\"\n",
    "    os.environ[\"LAUNCH_BY_NAME_analyzer_crnn\"] = \"1\"\n",
    "    os.environ[\"LAUNCH_BY_NAME_analyzer_tagger\"] = \"1\"\n",
    "    os.environ[\"LAUNCH_BY_NAME_detector_face\"] = \"1\"\n",
    "    os.environ[\"LAUNCH_Q_qclusterer\"] = \"1\"\n",
    "    os.environ[\"LAUNCH_Q_qextract\"] = \"1\"\n",
    "    os.environ[\"LAUNCH_SCHEDULER\"] = \"1\"\n",
    "    # export  TEST=1\n",
    "    os.environ[\"AUTH_DISABLED\"] = \"1\"\n",
    "    dva_home = \"/home/tom/ai/DeepVideoAnalytics\"\n",
    "    sys.path.append(os.path.abspath(dva_home))\n",
    "    \n",
    "    os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"dva.settings\")\n",
    "    django.setup()\n",
    "    \n",
    "start_local()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmp = \"/home/tom/ai.dataset.images/Face/222/222_0.bmp\"\n",
    "temppath = \"/home/tom/ai.dataset.images.tmp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Loading facenet , first apply / query will be slower\n",
      "WARNING:root:Creating a session facenet , first apply / query will be slower\n"
     ]
    }
   ],
   "source": [
    "import dvalib.indexer\n",
    "facenet_index = dvalib.indexer.FacenetIndexer(os.path.join(\n",
    "    \"/home/tom/ai/DeepVideoAnalytics/dva/media/indexers/2\",\n",
    "    \"facenet.pb\"))\n",
    "facenet_index.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 317.39971729  171.56318542  410.30632931  284.6099072 ]\n",
      "[295 149 432 306]\n"
     ]
    }
   ],
   "source": [
    "bmp = \"/home/tom/ai.dataset.images/Face/222/222_0.bmp\"\n",
    "from dvalib import detector\n",
    "reload(detector)\n",
    "detect =detector.FaceDetector()\n",
    "detect.load()\n",
    "import scipy.misc as misc\n",
    "faces = detect.crop(misc.imread(bmp))\n",
    "for face in faces :\n",
    "    misc.imshow(face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dvalib import retriever\n",
    "args = {}\n",
    "args[\"components\"] =16 # pca component\n",
    "args[\"m\"] = 4 # totol number of fine codes\n",
    "args[\"v\"] = 8 # number of cluster per coarse quntizer\n",
    "args[\"sub\"] = 256 # the number of cluster to train per subquantizer\n",
    "args['proto_filename'] = os.path.join(temppath, \"retriever.proto\")\n",
    "args['proto_filename'].replace('.proto','.P.npy')\n",
    "args['proto_filename'].replace('.proto','.mu.npy')\n",
    "args['proto_filename'].replace('.proto', '.pca.pkl')\n",
    "args['proto_filename'].replace('.proto', '_lmdb')\n",
    "args['proto_filename'].replace('.proto', '.permuted_inds.pkl')\n",
    "\n",
    "lopq = retriever.LOPQRetriever(\"lopq\", args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dvalib.dlib.align_dlib import AlignDlib\n",
    "reload(dvalib.dlib.align_dlib)\n",
    "def getLargestFace(in_path, out_path, face_predictor) :\n",
    "    import scipy\n",
    "    from scipy import misc\n",
    "    \n",
    "    if not os.path.exists(out_path):\n",
    "        os.mkdir(out_path)\n",
    "        \n",
    "    pics = os.listdir(in_path)\n",
    "    for pic in pics:\n",
    "        pic_path = os.path.join(in_path, pic)\n",
    "        image = misc.imread(pic_path)\n",
    "        bb = face_predictor.getLargestFaceBoundingBox(image, True)\n",
    "        al = face_predictor.align(96, image, bb)\n",
    "        if al is None:\n",
    "            print(\"faild to align={}\".format(pic_path))\n",
    "            pass\n",
    "        else :\n",
    "            cropfile = os.path.join(out_path, (pic.split(\".\"))[0]+\"_crop.png\")\n",
    "            misc.imsave(cropfile, al)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "facePredictor=/home/tom/ai/models/dlib/shape_predictor_68_face_landmarks.dat\n"
     ]
    }
   ],
   "source": [
    "face68 = AlignDlib(os.path.join(\"/home/tom/ai/models/dlib\",\"shape_predictor_68_face_landmarks.dat\"))\n",
    "getLargestFace(\"/home/tom/ai.dataset.images.tmp/test\", \"/home/tom/ai.dataset.images.tmp/test.face68\", face68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_DB_4_ms/110_0.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_DB_4_ms/251_2.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_DB_4_ms/137_3.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_DB_4_ms/257_3.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_DB_4_ms/340_3.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_DB_4_ms/464_2.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_DB_4_ms/135_3.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_DB_4_ms/157_4.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_DB_4_ms/464_0.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_DB_4_ms/284_4.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_DB_4_ms/471_2.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_DB_4_ms/254_2.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_DB_4_ms/257_2.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_DB_4_ms/464_1.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_DB_4_ms/127_0.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_DB_4_ms/464_3.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_DB_4_ms/121_0.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_DB_4_ms/367_3.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_DB_4_ms/121_4.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_DB_4_ms/438_1.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_DB_4_ms/402_4.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_DB_4_ms/123_1.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_DB_4_ms/136_0.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_DB_4_ms/339_4.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_DB_4_ms/251_1.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_DB_4_ms/152_4.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_DB_4_ms/262_1.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_DB_4_ms/257_4.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_DB_4_ms/113_3.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_DB_4_ms/295_0.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_DB_4_ms/323_0.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_DB_4_ms/193_4.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_DB_4_ms/113_1.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_DB_4_ms/362_0.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_DB_4_ms/262_3.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_DB_4_ms/379_4.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_DB_4_ms/254_3.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_DB_4_ms/347_0.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_DB_4_ms/003_4.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_DB_4_ms/129_1.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_DB_4_ms/366_1.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_DB_4_ms/070_3.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_DB_4_ms/071_4.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_DB_4_ms/185_3.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_DB_4_ms/209_4.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_DB_4_ms/122_4.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_DB_4_ms/101_0.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_DB_4_ms/090_4.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_DB_4_ms/262_4.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_Test_ms/258_2.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_Test_ms/185_0.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_Test_ms/113_2.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_Test_ms/464_4.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_Test_ms/131_2.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_Test_ms/145_1.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_Test_ms/381_1.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_Test_ms/459_4.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_Test_ms/019_4.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_Test_ms/181_3.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_Test_ms/080_4.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_Test_ms/209_1.png\n",
      "faild to align=/home/tom/ai.dataset.images.tmp/Face_Test_ms/254_4.png\n"
     ]
    }
   ],
   "source": [
    "getLargestFace(\"/home/tom/ai.dataset.images.tmp/Face_DB_4_ms\", \n",
    "               \"/home/tom/ai.dataset.images.tmp/Face_DB_4_ms.crop\",face68)\n",
    "getLargestFace(\"/home/tom/ai.dataset.images.tmp/Face_Test_ms\", \n",
    "               \"/home/tom/ai.dataset.images.tmp/Face_Test_ms.crop\",face68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dot(feat,feat)=1.00000011921\n",
      "dot(head, head)=1.00000011921\n",
      "dot(feat, head)=1.00000011921\n"
     ]
    }
   ],
   "source": [
    "import skimage.io as io\n",
    "import os.path\n",
    "from scipy import misc\n",
    "if not os.path.exists(temppath):\n",
    "    os.mkdir(temppath)\n",
    "basename = os.path.basename(bmp)\n",
    "dirname  = os.path.dirname(bmp)\n",
    "png = os.path.join(temppath, basename.split(\".\")[0] + \".png\")\n",
    "image = io.imread(bmp)\n",
    "io.imsave(png, image)\n",
    "#misc.imshow(image)\n",
    "\n",
    "import scipy\n",
    "from scipy import misc\n",
    "#misc.imshow(crop)\n",
    "bb = face68.getLargestFaceBoundingBox(image, True)\n",
    "\n",
    "al = face68.align(96, image, bb)\n",
    "#misc.imshow(al)\n",
    "\n",
    "cropfile = os.path.join(temppath, (basename.split('.')[0]+ \"_crop\"+\".png\"))\n",
    "io.imsave(cropfile, al)\n",
    "#detect.cropLargestToFile(png, cropfile)\n",
    "\n",
    "misc.imshow(al)\n",
    "\n",
    "feat      = np.squeeze(index.apply(png))\n",
    "feat_head = np.squeeze(index.apply(png))\n",
    "\n",
    "print(\"dot(feat,feat)={}\".format(np.dot(feat,feat)))\n",
    "print(\"dot(head, head)={}\".format(np.dot(feat_head, feat_head)))\n",
    "print(\"dot(feat, head)={}\".format(np.dot(feat, feat_head)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78230083"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import skimage.io as io\n",
    "import collections\n",
    "PicRec = collections.namedtuple(\"PicRec\",[\"path\",\"feat\"])\n",
    "def detect_dir(path, indexer) :\n",
    "    result = []\n",
    "    faces = os.listdir(path)\n",
    "    for f in faces:\n",
    "        picpath = os.path.join(path, f)\n",
    "        feat = np.squeeze(indexer.apply(picpath))\n",
    "        result.append(PicRec(path=f.split(\"_\")[0], feat=feat))\n",
    "        \n",
    "    return result\n",
    "\n",
    "\n",
    "dest_dir = \"/home/tom/ai.dataset.images.tmp/test.face68\"\n",
    "r = detect_dir(dest_dir, facenet_index)\n",
    "np.dot(r[0].feat, r[1].feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_face_dir = \"/home/tom/ai.dataset.images.tmp/Face_DB_4_ms.crop\"\n",
    "crop_test_dir = \"/home/tom/ai.dataset.images.tmp/Face_Test_ms.crop\"\n",
    "\n",
    "if not os.path.exists(crop_face_dir) :\n",
    "    os.mkdir(crop_face_dir)\n",
    "if not os.path.exists(crop_test_dir) :\n",
    "    os.mkdir(crop_test_dir)\n",
    "    \n",
    "#os.mkdir(crop_test_dir)\n",
    "valid = detect_dir(crop_test_dir, facenet_index)\n",
    "train = detect_dir(crop_face_dir, facenet_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1551, 128)\n",
      "(488, 128)\n"
     ]
    }
   ],
   "source": [
    "def save_feat(data, path):\n",
    "    feats = [ d.feat for d in data ]\n",
    "    arr = np.array(feats)\n",
    "    print(arr.shape)\n",
    "    np.save(path, arr)\n",
    "    \n",
    "save_feat(train, \"train_crop.npy\")\n",
    "save_feat(valid, \"valid_crop.npy\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1551, 128)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  2, 98, 46, 10, 86, 69, 74, 33, 16], dtype=int32),\n",
       " array([  1.19209290e-07,   1.06155872e-04,   6.92546368e-04,\n",
       "          8.81016254e-04,   1.38443708e-03,   1.84917450e-03,\n",
       "          6.77150488e-03,   6.82270527e-03,   1.46547556e-02,\n",
       "          1.81168318e-02], dtype=float32))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os.path\n",
    "import nmslib \n",
    "import numpy as np\n",
    "\n",
    "INDEX_DIR='indices'    \n",
    "import shutil\n",
    "if os.path.exists(INDEX_DIR):\n",
    "    shutil.rmtree(INDEX_DIR)\n",
    "\n",
    "class NmslibReuseIndex:\n",
    "    def __init__(self, metric, method_name, index_param, save_index, query_param):\n",
    "        self._nmslib_metric = {'angular': 'cosinesimil', 'euclidean': 'l2'}[metric]\n",
    "        self._method_name = method_name\n",
    "        self._save_index = save_index\n",
    "        self._index_param = index_param\n",
    "        self._query_param = query_param\n",
    "        self.name = 'Nmslib(method_name=%s, index_param=%s, query_param=%s)' % (\n",
    "            method_name, index_param, query_param)\n",
    "        \n",
    "        self._index_name = os.path.join(INDEX_DIR, \"nmslib_%s_%s_%s\" % (\n",
    "            self._method_name, metric, '_'.join(self._index_param))) \n",
    "\n",
    "        d = os.path.dirname(self._index_name)\n",
    "        if not os.path.exists(d):\n",
    "          os.makedirs(d)\n",
    "        \n",
    "        self._index = nmslib.init(self._nmslib_metric)\n",
    "\n",
    "    def add(self, i, x) :\n",
    "        self._index.addDataPoint(i,x)\n",
    "        \n",
    "    def fit(self, X):\n",
    "        if self._method_name == 'vptree':\n",
    "            # To avoid this issue:\n",
    "            # terminate called after throwing an instance of 'std::runtime_error'\n",
    "            # what():  The data size is too small or the bucket size is too big. Select the parameters so that <total # of records> is NOT less than <bucket size> * 1000\n",
    "            # Aborted (core dumped)\n",
    "            self._index_param.append('bucketSize=%d' % min(int(X.shape[0] * 0.0005), 1000))\n",
    "                                        \n",
    "        for i, x in enumerate(X):\n",
    "            self._index.addDataPoint(i, x)\n",
    "\n",
    "\n",
    "        if os.path.exists(self._index_name):\n",
    "            print \"Loading index from file\"\n",
    "            self._index.loadIndex(self._index_name)\n",
    "        else:\n",
    "            self._index.createIndex(self._index_param)\n",
    "            if self._save_index: \n",
    "              self._index.saveIndex(self._index_name)\n",
    "        #self._index.setQueryTimeParams(self._query_param)\n",
    "        \n",
    "\n",
    "    def query(self, v, n):\n",
    "        return self._index.knnQuery( v, k=n)\n",
    "\n",
    "    def freeIndex(self):\n",
    "        self._index = None\n",
    "        \n",
    "class FALCONN(object):\n",
    "    def __init__(self, metric, num_bits, num_tables, num_probes):\n",
    "        self.name = 'FALCONN(K={}, L={}, T={})'.format(num_bits, num_tables, num_probes)\n",
    "        self._metric = metric\n",
    "        self._num_bits = num_bits\n",
    "        self._num_tables = num_tables\n",
    "        self._num_probes = num_probes\n",
    "        self._center = None\n",
    "        self._params = None\n",
    "        self._index = None\n",
    "        self._buf = None\n",
    "\n",
    "    def fit(self, X):\n",
    "        if X.dtype != numpy.float32:\n",
    "            X = X.astype(numpy.float32)\n",
    "        if self._metric == 'angular':\n",
    "            X /= numpy.linalg.norm(X, axis=1).reshape(-1,  1)\n",
    "        self._center = numpy.mean(X, axis=0)\n",
    "        X -= self._center\n",
    "        import falconn\n",
    "        self._params = falconn.LSHConstructionParameters()\n",
    "        self._params.dimension = X.shape[1]\n",
    "        self._params.distance_function = 'euclidean_squared'\n",
    "        self._params.lsh_family = 'cross_polytope'\n",
    "        falconn.compute_number_of_hash_functions(self._num_bits, self._params)\n",
    "        self._params.l = self._num_tables\n",
    "        self._params.num_rotations = 1\n",
    "        self._params.num_setup_threads = 0\n",
    "        self._params.storage_hash_table = 'flat_hash_table'\n",
    "        self._params.seed = 95225714\n",
    "        self._index = falconn.LSHIndex(self._params)\n",
    "        self._index.setup(X)\n",
    "        self._index.set_num_probes(self._num_probes)\n",
    "        self._buf = numpy.zeros((X.shape[1],), dtype=numpy.float32)\n",
    "\n",
    "    def query(self, v, n):\n",
    "        numpy.copyto(self._buf, v)\n",
    "        if self._metric == 'angular':\n",
    "            self._buf /= numpy.linalg.norm(self._buf)\n",
    "        self._buf -= self._center\n",
    "        return self._index.find_k_nearest_neighbors(self._buf, n)\n",
    "\n",
    "data = np.random.randn(100, 2).astype(np.float32)\n",
    "index = NmslibReuseIndex(\"angular\", \"hnsw\", {\"post\":2}, False, {\"k\":10})\n",
    "index.fit(data)\n",
    "index.query(data[0], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = NmslibReuseIndex(\"euclidean\", \"hnsw\", {\"post\":2}, False, {\"k\":10})\n",
    "names = []\n",
    "for i, (name,feat) in enumerate(train):\n",
    "    index.add(i, feat)\n",
    "    names.append(name)\n",
    "\n",
    "index.fit([])\n",
    "\n",
    "RecRec = collections.namedtuple(\"RecRec\",[\"target\",\"result\", \"similarity\"])\n",
    "query= []\n",
    "for i, (name, feat) in enumerate(valid):\n",
    "    r = index.query(feat, 1)\n",
    "    if len(r[0]) > 0:\n",
    "        rec = RecRec(target=name, result=names[r[0][0]], similarity=1.0-r[1][0])\n",
    "    else:\n",
    "        rec = RecRec(target=name, result=\"\", similarity=0.0)\n",
    "    query.append(rec)\n",
    "    \n",
    "face_test_f1_dir = \"/home/tom/ai.dataset.images/face_test_f1\"\n",
    "fn = os.path.join(face_test_f1_dir, \"facenet_test.csv\")\n",
    "with open(fn,\"w\") as f:\n",
    "    f.write(\"target,result,similarity\\n\")\n",
    "    for target, result, similarity in query:\n",
    "        f.write(\"{},{},{}\\n\".format(target, result,similarity))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_names_path = \"db_names.txt\"       \n",
    "db_feats_path = \"db_feats.txt\"\n",
    "def save_index(featpath, namepath, nf):\n",
    "    with open(featpath,\"w\") as f:\n",
    "        with open(namepath,\"w\") as fnames:\n",
    "            for i, (name, feat) in enumerate(nf):\n",
    "                fnames.write(\"{}\\n\".format(name))\n",
    "                f.write(\"{},{}\\n\".format(name, \",\".join([ str(featvalue) for featvalue in feat])))\n",
    "save_index( \"db_feats.txt\", \"db_names.txt\", train)\n",
    "save_index( \"va_feats.txt\", \"va_names.txt\", valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1551, 128)\n",
      "1551\n",
      "{'index': 856, 'fine': (6, 24, 15, 0, 27, 1, 16, 6), 'name': '210', 'coarse': (1, 1)}\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "Attempt to operate on closed/deleted/dropped object.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-4a3ff51e8950>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mretriever\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mretriever\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mretriever\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/tom/z.git.github.beautycpp.ai/DeepVideoAnalytics/dvalib/retriever.pyc\u001b[0m in \u001b[0;36mfind\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mselected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0mselected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result_quota\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/lopq-1.0.1843-py2.7.egg/lopq/search.pyc\u001b[0m in \u001b[0;36mget_result_quota\u001b[0;34m(self, x, quota)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mvisited\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmultisequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mretrieved\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0mvisited\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/lopq-1.0.1843-py2.7.egg/lopq/search.pyc\u001b[0m in \u001b[0;36mget_cell\u001b[0;34m(self, cell)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_db\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtxn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m             \u001b[0mcursor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtxn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mError\u001b[0m: Attempt to operate on closed/deleted/dropped object."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "train_feat = np.load(\"train_crop.npy\")\n",
    "print(train_feat.shape)\n",
    "names=[]\n",
    "with open(\"db_names.txt\") as f:\n",
    "    names = [{\"name\":name.split(\"\\n\")[0]} for name in f]\n",
    "print(len(names))\n",
    "import dvalib\n",
    "from dvalib.retriever import LOPQRetriever\n",
    "reload(dvalib.retriever)\n",
    "retriever = LOPQRetriever.create(\"lopq\", train_feat, names, 8, 8, 4, 32, \"lopq\")\n",
    "retriever.cluster()\n",
    "retriever.save()\n",
    "retriever.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03988038,  0.02231823,  0.09309283,  0.06220671, -0.10856172,\n",
       "         0.06130679, -0.0200982 , -0.06013606, -0.20054638,  0.03027017,\n",
       "         0.07305267,  0.00332147, -0.0808949 ,  0.12775208,  0.02128939,\n",
       "        -0.0087125 ,  0.13576651,  0.03005937,  0.08387784,  0.05591175,\n",
       "        -0.09911769,  0.0099276 , -0.04575694,  0.01198979,  0.07159621,\n",
       "         0.04630898,  0.06588056, -0.00839717, -0.07564819, -0.05096553,\n",
       "         0.05005041,  0.02391338,  0.0027637 ,  0.00998749,  0.09618499,\n",
       "         0.09822913,  0.13379873, -0.12946035, -0.1466385 ,  0.00965519,\n",
       "        -0.1069741 , -0.0622725 , -0.03112246,  0.05175905, -0.07371196,\n",
       "         0.05412187, -0.08798917, -0.1624358 , -0.07194415,  0.04252998,\n",
       "         0.02636459,  0.09459836,  0.02199816, -0.04750916,  0.06851123,\n",
       "        -0.06449898,  0.19184849,  0.07630563,  0.02654444,  0.05355344,\n",
       "         0.05333633,  0.07897984,  0.04818605,  0.14577231,  0.07075949,\n",
       "         0.01076952,  0.10421053,  0.03754625, -0.02894439, -0.00695633,\n",
       "         0.01393869, -0.10935871,  0.00493409, -0.02799521,  0.03398739,\n",
       "         0.02188493,  0.24031048,  0.13314581, -0.06424524,  0.13281192,\n",
       "         0.08561477, -0.08969565, -0.06006044,  0.02598018, -0.03350074,\n",
       "        -0.21973352, -0.038973  , -0.11976557, -0.07711691,  0.06643266,\n",
       "        -0.12253068, -0.01570663, -0.08813101, -0.18101221, -0.01022597,\n",
       "         0.05797307,  0.04092607,  0.03932227, -0.02611241, -0.08618726,\n",
       "         0.06739213, -0.01540174, -0.11327887, -0.08167085,  0.05009478,\n",
       "        -0.0327202 ,  0.07883348, -0.07560203,  0.08927052, -0.03732838,\n",
       "         0.05775828, -0.00177554,  0.15847248, -0.18461251,  0.00961928,\n",
       "         0.17391503, -0.09860555,  0.15832745, -0.04261712, -0.09227204,\n",
       "         0.06652072,  0.20062231,  0.03351228,  0.02313809,  0.18189009,\n",
       "         0.08461945,  0.13199814,  0.01586674]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat=train_feat[0,:]\n",
    "np.expand_dims(feat,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse, fine, result = retriever.apply(np.expand_dims(train_feat[0,:],axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coarse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, 5, 8, 16, 12, 16, 2, 20)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'index': 601, 'fine': (14, 10, 16, 17, 27, 10, 10, 3), 'name': '122', 'coarse': (0, 0)}\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "Attempt to operate on closed/deleted/dropped object.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-f78dd9006b61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mretriever\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/tom/z.git.github.beautycpp.ai/DeepVideoAnalytics/dvalib/retriever.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mselected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0mselected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result_quota\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/lopq-1.0.1843-py2.7.egg/lopq/search.pyc\u001b[0m in \u001b[0;36mget_result_quota\u001b[0;34m(self, x, quota)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mvisited\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmultisequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mretrieved\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0mvisited\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/lopq-1.0.1843-py2.7.egg/lopq/search.pyc\u001b[0m in \u001b[0;36mget_cell\u001b[0;34m(self, cell)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_db\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtxn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m             \u001b[0mcursor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtxn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mError\u001b[0m: Attempt to operate on closed/deleted/dropped object."
     ]
    }
   ],
   "source": [
    "retriever.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
